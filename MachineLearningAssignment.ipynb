{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "psYOrQK2C4m2"
   },
   "source": [
    "# MediaEval: Predicting Media Memorability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rm3D6MWRHNsr"
   },
   "source": [
    "## 1.0 Setup\n",
    "### 1.1 Importing common libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "oP5ECsXwHzAj",
    "outputId": "3ba44c89-8d56-47d0-d636-07482945497c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyprind\n",
    "import os\n",
    "import nltk\n",
    "import multiprocessing as mp\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import pickle\n",
    "\n",
    "stopwords_list = nltk.corpus.stopwords.words('english')\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Re-usable Function Definitions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "#Loads captions file from given location\n",
    "def load_captions(path):\n",
    "    video_name = []\n",
    "    captions = []\n",
    "    dataframe = pd.DataFrame()\n",
    "    pbar = pyprind.ProgBar(6000,title='Captions Loading Progress')\n",
    "    with open(path) as file:\n",
    "        for line in file:\n",
    "            pair = line.split()\n",
    "            video_name.append(pair[0])\n",
    "            captions.append(pair[1])\n",
    "            pbar.update()\n",
    "        dataframe['video']=video_name\n",
    "        dataframe['caption']=captions\n",
    "    return dataframe\n",
    "\n",
    "#Loads c3d feature files from given location\n",
    "def load_c3d_features(captions, path):\n",
    "    files = list(captions[\"video\"].values)\n",
    "    c3dFeatures = []\n",
    "    pbar = pyprind.ProgBar(len(captions['caption']),title='C3D Features Loading Progress')\n",
    "    for file in files:\n",
    "        file = path+file[:-4]+'txt'\n",
    "        c3dFeatures.append(np.loadtxt(file))\n",
    "        pbar.update()\n",
    "    return c3dFeatures\n",
    "\n",
    "#Loads HMP features file from given location\n",
    "\n",
    "def load_hmp_features(captions, path):\n",
    "    files = list(captions[\"video\"].values)\n",
    "    hmp_features = []\n",
    "    pbar = pyprind.ProgBar(len(captions['caption']),title='HMP Features Loading Progress')\n",
    "    for file in files:\n",
    "        file = path+file[:-4]+'txt'\n",
    "        pbar.update()\n",
    "        with open(file) as f:\n",
    "            for line in f:\n",
    "                pairs=line.split()\n",
    "                hmp_temp = { int(p.split(':')[0]) : float(p.split(':')[1]) for p in pairs}\n",
    "                hmp = np.zeros(6075)\n",
    "            for idx in hmp_temp.keys():\n",
    "                hmp[idx-1] = hmp_temp[idx]\n",
    "            hmp_features.append(hmp)\n",
    "    return hmp_features\n",
    "\n",
    "# Cleans and vectorises captions\n",
    "\n",
    "def clean_create_caption_vector(captions):\n",
    "    pbar = pyprind.ProgBar(len(captions['caption']), title='Counting word occurrences')\n",
    "\n",
    "    for i, cap in enumerate(captions['caption']):\n",
    "        text = ''.join([c if c not in punctuation else ' ' for c in cap]).lower()\n",
    "        captions_with_stopwords_removed= ' '.join([word for word in text.split() if word not in stopwords_list])\n",
    "        captions.loc[i,'caption'] = captions_with_stopwords_removed\n",
    "        pbar.update()\n",
    "\n",
    "    #implementing bag of words for the combined captions\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",max_features=3112)\n",
    "    captions_bag = vectorizer.fit_transform(captions.caption).toarray()\n",
    "    return captions_bag\n",
    "\n",
    "# Function to calculate Spearman coefficient scores\n",
    "\n",
    "def spearman_score(Y_pred,Y_true):\n",
    "    Y_pred = np.squeeze(Y_pred)\n",
    "    Y_true = np.squeeze(Y_true)\n",
    "    if Y_pred.shape != Y_true.shape:\n",
    "        print('Input shapes don\\'t match!')\n",
    "    else:\n",
    "        if len(Y_pred.shape) == 1:\n",
    "            Res = pd.DataFrame({'Y_true':Y_true,'Y_pred':Y_pred})\n",
    "            score_mat = Res[['Y_true','Y_pred']].corr(method='spearman',min_periods=1)\n",
    "            print('The Spearman\\'s correlation coefficient is: %.3f' % score_mat.iloc[1][0])\n",
    "        else:\n",
    "            for ii in range(Y_pred.shape[1]):\n",
    "                spearman_score(Y_pred[:,ii],Y_true[:,ii])\n",
    "\n",
    "# Utility function for combining data\n",
    "\n",
    "def combine_dataset(first_set,second_set, len:int):\n",
    "    combined_set = first_set\n",
    "    pbar = pyprind.ProgBar(len, title='Combining dataset')\n",
    "    for counter in range(len):\n",
    "        combined_set[counter] = np.append(combined_set[counter],second_set[counter],axis=0)\n",
    "        pbar.update()\n",
    "    return combined_set\n",
    "\n",
    "# Build and score random forest model on given training data\n",
    "\n",
    "def random_forest_score(x,y):\n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "    rf_regressor = RandomForestRegressor(n_estimators=100,random_state=45,verbose=1,n_jobs=8)\n",
    "\n",
    "    rf_regressor.fit(x_train,y_train)\n",
    "\n",
    "    rf_pred = rf_regressor.predict(x_test)\n",
    "\n",
    "    spearman_score(rf_pred, y_test)\n",
    "\n",
    "# Build and score SVR model on given training data after scaling\n",
    "\n",
    "def svr_regression_scaled_score(x,y):\n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "    x_scaler= StandardScaler()\n",
    "    y_scaler= StandardScaler()\n",
    "\n",
    "    x_train_scaled=x_scaler.fit_transform(x_train);\n",
    "    y_train_scaled=y_scaler.fit_transform(y_train);\n",
    "\n",
    "    svr_regressor = SVR(kernel = 'rbf',cache_size=4096)\n",
    "\n",
    "    svr_regressor.fit(x_train_scaled, y_train_scaled)\n",
    "\n",
    "    y_pred_scaled = svr_regressor.predict(x_test)\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "    spearman_score(y_pred, y_test)\n",
    "\n",
    "# Build and score SVR model on given training data without scaling\n",
    "\n",
    "def svr_regression_score(x,y):\n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "    svr_regressor = SVR(kernel = 'rbf')\n",
    "\n",
    "    svr_regressor.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = svr_regressor.predict(x_test)\n",
    "\n",
    "    spearman_score(y_pred, y_test)\n",
    "\n",
    "# Build and return SVR model and scales\n",
    "\n",
    "def svr_regression_scaled_final(x,y):\n",
    "    x_scaler= StandardScaler()\n",
    "    y_scaler= StandardScaler()\n",
    "\n",
    "    x_scaled=x_scaler.fit_transform(x);\n",
    "    y_scaled=y_scaler.fit_transform(y);\n",
    "\n",
    "    svr_regressor = SVR(kernel = 'rbf')\n",
    "\n",
    "    svr_regressor.fit(x_scaled, y_scaled)\n",
    "\n",
    "    return svr_regressor,x_scaler,y_scaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "DSrpLYQhDMBM",
    "outputId": "39dae0cb-4a1b-4b31-ad02-b8c1a268c98d",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Path Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "os.chdir('D:/CA684_AssignmentData')\n",
    "\n",
    "ground_truth_path ='./Dev-set/Ground-truth/ground-truth.csv'\n",
    "captions_path='./Dev-set/Captions/dev-set_video-captions.txt'\n",
    "c3d_path = './Dev-set/C3D/'\n",
    "hmp_path = './Dev-set/HMP/'\n",
    "\n",
    "test_ground_truth_template_path ='./Test-set/Ground-truth/ground_truth_template.csv'\n",
    "test_captions_path ='./Test-set/Captions/test-set_video-captions.txt'\n",
    "test_c3d_path = './Test-set/C3D/'\n",
    "test_hmp_path = './Test-set/HMP/'\n",
    "\n",
    "final_short_model_dump = 'final_short_term_model.sav'\n",
    "final_long_model_dump = 'final_long_term_model.sav'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xI_s6_VvGsbf"
   },
   "source": [
    "## 2.0 Data Loading\n",
    "### 2.1 Loading Ground Truth Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "text",
    "id": "awQ-k8MvGi4p",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv(ground_truth_path)\n",
    "y_combined = ground_truth[['short-term_memorability','long-term_memorability']].values\n",
    "y_short = ground_truth[['short-term_memorability']].values\n",
    "y_long = ground_truth[['long-term_memorability']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0s-gRXA3zxnQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 Loading Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "text",
    "id": "bZGOlEC2IU-f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Captions Loading Progress\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "captions = load_captions(captions_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "z5mGI34ADZaP",
    "outputId": "81794cf1-4c1c-4545-ca6c-b99045fc29a8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.3 Loading C3D Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "text",
    "id": "3cER4T7wIPbq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C3D Features Loading Progress\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    }
   ],
   "source": [
    "c3d_features = load_c3d_features(captions,c3d_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Loading HMP Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "HQE0q5_jqx-q",
    "outputId": "7f7e5128-597e-46c4-be59-6be043e91781"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HMP Features Loading Progress\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:22\n"
     ]
    }
   ],
   "source": [
    "hmp_features = load_hmp_features(captions,hmp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYSy1dezJeRS"
   },
   "source": [
    "## 3.0 Data Pre-processing\n",
    "### 3.1 Cleaning Captions & vectoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting word occurrences\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "captions_bag=clean_create_caption_vector(captions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGh8o0V9NEwC"
   },
   "source": [
    "### 3.2 Combining Captions + C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining dataset\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    }
   ],
   "source": [
    "captions_c3d_bag=combine_dataset(captions_bag.tolist(),c3d_features,len(captions['caption']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Combining Captions + C3D + HMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining dataset\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "captions_c3d_hmp_bag=combine_dataset(captions_c3d_bag,hmp_features,len(captions['caption']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Training and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Random Forest with Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:  4.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.409\n",
      "The Spearman's correlation coefficient is: 0.176\n"
     ]
    }
   ],
   "source": [
    "random_forest_score(captions_bag,y_combined);"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2 SVR with Captions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\akhil\\pycharmprojects\\videomemorability\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\akhil\\pycharmprojects\\videomemorability\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.418\n",
      "The Spearman's correlation coefficient is: 0.199\n"
     ]
    }
   ],
   "source": [
    "svr_regression_scaled_score(captions_bag,y_short)\n",
    "svr_regression_scaled_score(captions_bag,y_long)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3 Random Forest with Captions + C3D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:  4.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.322\n",
      "The Spearman's correlation coefficient is: 0.145\n"
     ]
    }
   ],
   "source": [
    "random_forest_score(captions_c3d_bag,y_combined)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4 SVR with Captions + C3D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\akhil\\pycharmprojects\\videomemorability\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\akhil\\pycharmprojects\\videomemorability\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.446\n",
      "The Spearman's correlation coefficient is: 0.192\n"
     ]
    }
   ],
   "source": [
    "svr_regression_scaled_score(captions_c3d_bag,y_short)\n",
    "svr_regression_scaled_score(captions_c3d_bag,y_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.5 Random Forest with Captions + C3D + HMP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:  8.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.322\n",
      "The Spearman's correlation coefficient is: 0.145\n"
     ]
    }
   ],
   "source": [
    "random_forest_score(captions_c3d_hmp_bag,y_combined)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.6 SVR with Captions + C3D + HMP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\akhil\\pycharmprojects\\videomemorability\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\akhil\\pycharmprojects\\videomemorability\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman's correlation coefficient is: 0.446\n",
      "The Spearman's correlation coefficient is: 0.192\n"
     ]
    }
   ],
   "source": [
    "svr_regression_scaled_score(captions_c3d_hmp_bag,y_short)\n",
    "svr_regression_scaled_score(captions_c3d_hmp_bag,y_long)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.0 Comparison of Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.0 Building & Pickling Final Model\n",
    "\n",
    "### 6.1 Training Full Dev-Set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\akhil\\pycharmprojects\\videomemorability\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "final_short_term_mem_regressor,input_short_scale,pred_short_scale=svr_regression_scaled_final(captions_c3d_bag,y_short)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\akhil\\pycharmprojects\\videomemorability\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:744: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "final_long_term_mem_regressor,input_long_scale,pred_long_scale=svr_regression_scaled_final(captions_bag,y_long)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2 Importing test dataset for predicting memorability scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Captions Loading Progress\n",
      "0% [#########                     ] 100% | ETA: 00:00:00C3D Features Loading Progress\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n",
      "HMP Features Loading Progress\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:12\n",
      "Counting word occurrences\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n",
      "Combining dataset\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n",
      "Combining dataset\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#Loading Test Data\n",
    "test_dataset = pd.read_csv(test_ground_truth_template_path)\n",
    "test_captions = load_captions(test_captions_path)\n",
    "\n",
    "test_c3d_features=load_c3d_features(test_captions,test_c3d_path)\n",
    "test_hmp_features=load_hmp_features(test_captions,test_hmp_path)\n",
    "\n",
    "# Cleaning and reformatting data\n",
    "test_captions_bag=clean_create_caption_vector(test_captions)\n",
    "test_captions_c3d_bag=combine_dataset(test_captions_bag.tolist(),test_c3d_features,len(test_captions['caption']))\n",
    "test_captions_c3d_hmp_bag=combine_dataset(test_captions_c3d_bag,test_hmp_features,len(test_captions['caption']))\n",
    "\n",
    "\n",
    "test_short_pred = final_short_term_mem_regressor.predict(input_short_scale.fit_transform(test_captions_c3d_hmp_bag))\n",
    "test_long_pred = final_long_term_mem_regressor.predict(input_long_scale.fit_transform(test_captions_c3d_bag))\n",
    "\n",
    "test_dataset['short-term_memorability']=pred_short_scale.inverse_transform(test_short_pred)\n",
    "test_dataset['long-term_memorability']=pred_long_scale.inverse_transform(test_long_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.3 Saving memorability scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "              video  short-term_memorability  nb_short-term_annotations  \\\ncount   2000.000000              2000.000000                2000.000000   \nmean    8760.857500                 0.866521                  36.228500   \nstd      730.600388                 0.022438                   8.407237   \nmin     7494.000000                 0.785250                  30.000000   \n25%     8125.500000                 0.852787                  33.000000   \n50%     8769.000000                 0.867929                  33.000000   \n75%     9399.250000                 0.881605                  34.000000   \nmax    10008.000000                 0.940639                  99.000000   \n\n       long-term_memorability  nb_long-term_annotations  \ncount             2000.000000               2000.000000  \nmean                 0.790199                 12.788000  \nstd                  0.030152                  3.672983  \nmin                  0.681154                  9.000000  \n25%                  0.770721                 10.000000  \n50%                  0.790767                 12.000000  \n75%                  0.810492                 14.000000  \nmax                  0.879377                 39.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video</th>\n      <th>short-term_memorability</th>\n      <th>nb_short-term_annotations</th>\n      <th>long-term_memorability</th>\n      <th>nb_long-term_annotations</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>8760.857500</td>\n      <td>0.866521</td>\n      <td>36.228500</td>\n      <td>0.790199</td>\n      <td>12.788000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>730.600388</td>\n      <td>0.022438</td>\n      <td>8.407237</td>\n      <td>0.030152</td>\n      <td>3.672983</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>7494.000000</td>\n      <td>0.785250</td>\n      <td>30.000000</td>\n      <td>0.681154</td>\n      <td>9.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8125.500000</td>\n      <td>0.852787</td>\n      <td>33.000000</td>\n      <td>0.770721</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>8769.000000</td>\n      <td>0.867929</td>\n      <td>33.000000</td>\n      <td>0.790767</td>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>9399.250000</td>\n      <td>0.881605</td>\n      <td>34.000000</td>\n      <td>0.810492</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10008.000000</td>\n      <td>0.940639</td>\n      <td>99.000000</td>\n      <td>0.879377</td>\n      <td>39.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.to_csv(\"test_results_ground_truth.csv\",index=False)\n",
    "test_dataset.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7.0 Saving final model for future"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "pickle.dump(final_short_term_mem_regressor, open(final_short_model_dump, 'wb'))\n",
    "pickle.dump(final_long_term_mem_regressor, open(final_long_model_dump, 'wb'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "name": "MachineLearningAssignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}